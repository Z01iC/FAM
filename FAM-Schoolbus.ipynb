{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "WX_schoolbus.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Pretrained VGG\n",
        "\n",
        "https://pytorch.org/vision/stable/models.html"
      ],
      "metadata": {
        "id": "8hMpwz7dPx46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import collections\n",
        "from typing import DefaultDict, Tuple, List\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from torch.nn.modules.loss import L1Loss\n",
        "import time\n",
        "\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16', pretrained=True)\n",
        "\n",
        "use_cuda = True\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "JVaUZCnVNP35",
        "execution": {
          "iopub.status.busy": "2022-05-21T13:45:18.220119Z",
          "iopub.execute_input": "2022-05-21T13:45:18.220461Z",
          "iopub.status.idle": "2022-05-21T13:45:30.180522Z",
          "shell.execute_reply.started": "2022-05-21T13:45:18.220384Z",
          "shell.execute_reply": "2022-05-21T13:45:30.179788Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating labeled feature patch from test image manually"
      ],
      "metadata": {
        "id": "VA5UU_ujE17-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Download images\n",
        "!gdown --id '161Fw55U_Ng_o0uirdwBle5g2Fpl1qRqR'\n",
        "!unzip schoolbus.zip"
      ],
      "metadata": {
        "id": "OveNP7cqYeUZ",
        "execution": {
          "iopub.status.busy": "2022-05-21T13:46:06.226735Z",
          "iopub.execute_input": "2022-05-21T13:46:06.227022Z",
          "iopub.status.idle": "2022-05-21T13:46:13.207652Z",
          "shell.execute_reply.started": "2022-05-21T13:46:06.226986Z",
          "shell.execute_reply": "2022-05-21T13:46:13.206730Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## preprocess image\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "\n",
        "def black_image_outside_patch(img, top_left_x, top_left_y, bot_right_x, bot_right_y):\n",
        "    \"\"\"Blacks image outside provided bounding box\n",
        "    ----------\n",
        "    img:\n",
        "        image tensor\n",
        "\n",
        "    top_left_x, top_left_y, bot_right_x, bot_right_y:\n",
        "        coordinates of bounding box for patch to keep\n",
        "    Returns\n",
        "    -------\n",
        "    img_copy:\n",
        "        copy of the image with everything blacked out besides \n",
        "    \"\"\"\n",
        "    img_copy = img.detach().clone()\n",
        "    img_copy[:,:,:top_left_x] = 0\n",
        "    img_copy[:,:,bot_right_x:] = 0\n",
        "    img_copy[:,:top_left_y,:] = 0\n",
        "    img_copy[:,bot_right_y:,:] = 0\n",
        "    return img_copy\n",
        "\n",
        "def random_noise_outside_patch(img, top_left_x, top_left_y, bot_right_x, bot_right_y):\n",
        "    img_copy = img.detach().clone()\n",
        "    img_copy[:,:,:top_left_x] = torch.randn(img[:,:,:top_left_x].size())\n",
        "    img_copy[:,:,bot_right_x:] = torch.randn(img[:,:,bot_right_x:].size())\n",
        "    img_copy[:,:top_left_y,:] = torch.randn(img[:,:top_left_y,:].size())\n",
        "    img_copy[:,bot_right_y:,:] = torch.randn(img[:,bot_right_y:,:].size())\n",
        "    return img_copy\n",
        "\n",
        "def show(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
        "\n"
      ],
      "metadata": {
        "id": "NXgvQeIVPzqw",
        "execution": {
          "iopub.status.busy": "2022-05-21T13:46:15.279519Z",
          "iopub.execute_input": "2022-05-21T13:46:15.280228Z",
          "iopub.status.idle": "2022-05-21T13:46:15.292155Z",
          "shell.execute_reply.started": "2022-05-21T13:46:15.280187Z",
          "shell.execute_reply": "2022-05-21T13:46:15.291463Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wheels = []\n",
        "labels = []  ## \"School Bus\" text\n",
        "mirrors = []\n",
        "windshields = []\n",
        "sides = []  ## Side of school bus with many windows\n",
        "\n",
        "\n",
        "def append_features(wheel, label, mirror, windshield, side):\n",
        "    if wheel is not None:\n",
        "        wheels.append(wheel.to(device))\n",
        "    if label is not None:\n",
        "        labels.append(label.to(device))\n",
        "    if mirror is not None:\n",
        "        mirrors.append(mirror.to(device))\n",
        "    if windshield is not None:\n",
        "        windshields.append(windshield.to(device))\n",
        "    if side is not None:\n",
        "        sides.append(side.to(device))"
      ],
      "metadata": {
        "id": "RhlMk68wYwE-",
        "execution": {
          "iopub.status.busy": "2022-05-21T13:46:16.924185Z",
          "iopub.execute_input": "2022-05-21T13:46:16.924675Z",
          "iopub.status.idle": "2022-05-21T13:46:16.931466Z",
          "shell.execute_reply.started": "2022-05-21T13:46:16.924622Z",
          "shell.execute_reply": "2022-05-21T13:46:16.930624Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = str(1) + '.jpg'\n",
        "input_image = Image.open(filename)\n",
        "input_tensor = preprocess(input_image)\n",
        "show(input_tensor)\n",
        "wheel = random_noise_outside_patch(input_tensor, 70, 125, 125, 215).unsqueeze(0)\n",
        "label = random_noise_outside_patch(input_tensor, 100, 25, 160, 50).unsqueeze(0)\n",
        "mirror = random_noise_outside_patch(input_tensor, 125, 55, 160, 130).unsqueeze(0)\n",
        "windshield = random_noise_outside_patch(input_tensor, 80, 40, 200, 100).unsqueeze(0)\n",
        "side = random_noise_outside_patch(input_tensor, 0, 40, 100, 170).unsqueeze(0)\n",
        "append_features(wheel, label, mirror, windshield, side)"
      ],
      "metadata": {
        "id": "YcCu_cxqXbXg",
        "execution": {
          "iopub.status.busy": "2022-05-21T13:46:18.309144Z",
          "iopub.execute_input": "2022-05-21T13:46:18.309407Z",
          "iopub.status.idle": "2022-05-21T13:46:18.760518Z",
          "shell.execute_reply.started": "2022-05-21T13:46:18.309380Z",
          "shell.execute_reply": "2022-05-21T13:46:18.759781Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = str(2) + '.jpg'\n",
        "input_image = Image.open(filename)\n",
        "input_tensor = preprocess(input_image)\n",
        "show(input_tensor)\n",
        "wheel = random_noise_outside_patch(input_tensor, 75, 150, 120, 210).unsqueeze(0)\n",
        "label = random_noise_outside_patch(input_tensor, 40, 50, 90, 90).unsqueeze(0)\n",
        "mirror = random_noise_outside_patch(input_tensor, 50, 100, 75, 150).unsqueeze(0)\n",
        "windshiled = random_noise_outside_patch(input_tensor, 20, 80, 120, 120).unsqueeze(0)\n",
        "side = random_noise_outside_patch(input_tensor, 110, 75, 210, 175).unsqueeze(0)\n",
        "append_features(wheel, label, mirror, windshield, side)"
      ],
      "metadata": {
        "id": "xsdXHgiSa0xe",
        "execution": {
          "iopub.status.busy": "2022-05-21T13:46:19.229393Z",
          "iopub.execute_input": "2022-05-21T13:46:19.229937Z",
          "iopub.status.idle": "2022-05-21T13:46:19.695382Z",
          "shell.execute_reply.started": "2022-05-21T13:46:19.229884Z",
          "shell.execute_reply": "2022-05-21T13:46:19.694747Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = str(3) + '.jpg'\n",
        "input_image = Image.open(filename)\n",
        "input_tensor = preprocess(input_image)\n",
        "show(input_tensor)\n",
        "wheel = random_noise_outside_patch(input_tensor, 75, 120, 140, 210).unsqueeze(0)\n",
        "label = random_noise_outside_patch(input_tensor, 120, 0, 190, 30).unsqueeze(0)\n",
        "mirror = random_noise_outside_patch(input_tensor, 140, 50, 180, 130).unsqueeze(0)\n",
        "windshield = random_noise_outside_patch(input_tensor, 100, 20, 220, 100).unsqueeze(0)\n",
        "side = random_noise_outside_patch(input_tensor, 0, 0, 100, 180).unsqueeze(0)\n",
        "append_features(wheel, label, mirror, windshield, side)"
      ],
      "metadata": {
        "id": "TA8EoEe2cDiG",
        "execution": {
          "iopub.status.busy": "2022-05-21T13:46:20.253023Z",
          "iopub.execute_input": "2022-05-21T13:46:20.253540Z",
          "iopub.status.idle": "2022-05-21T13:46:20.569682Z",
          "shell.execute_reply.started": "2022-05-21T13:46:20.253504Z",
          "shell.execute_reply": "2022-05-21T13:46:20.569044Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = str(4) + '.jpg'\n",
        "input_image = Image.open(filename)\n",
        "input_tensor = preprocess(input_image)\n",
        "show(input_tensor)\n",
        "wheel = random_noise_outside_patch(input_tensor, 30, 135, 90, 220).unsqueeze(0)\n",
        "label = random_noise_outside_patch(input_tensor, 0, 25, 50, 55).unsqueeze(0)\n",
        "mirror = random_noise_outside_patch(input_tensor, 0, 60, 35, 130).unsqueeze(0)\n",
        "windshield = random_noise_outside_patch(input_tensor, 0, 45, 70, 110).unsqueeze(0)\n",
        "side = random_noise_outside_patch(input_tensor, 80, 25, 220, 180).unsqueeze(0)\n",
        "append_features(wheel, label, mirror, windshield, side)"
      ],
      "metadata": {
        "id": "X4Od1QMpcRqc",
        "execution": {
          "iopub.status.busy": "2022-05-21T13:46:21.178878Z",
          "iopub.execute_input": "2022-05-21T13:46:21.179436Z",
          "iopub.status.idle": "2022-05-21T13:46:21.426424Z",
          "shell.execute_reply.started": "2022-05-21T13:46:21.179399Z",
          "shell.execute_reply": "2022-05-21T13:46:21.425778Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = str(5) + '.jpg'\n",
        "input_image = Image.open(filename)\n",
        "input_tensor = preprocess(input_image)\n",
        "show(input_tensor)\n",
        "wheel = random_noise_outside_patch(input_tensor, 120, 160, 150, 220).unsqueeze(0)\n",
        "label = random_noise_outside_patch(input_tensor, 70, 60, 120, 90).unsqueeze(0)\n",
        "mirror = random_noise_outside_patch(input_tensor, 110, 115, 140, 160).unsqueeze(0)\n",
        "windshield = random_noise_outside_patch(input_tensor, 40, 85, 150, 125).unsqueeze(0)\n",
        "side = random_noise_outside_patch(input_tensor, 145, 75, 220, 190).unsqueeze(0)\n",
        "append_features(wheel, label, mirror, windshield, side)"
      ],
      "metadata": {
        "id": "_CV1tcfjfGi6",
        "execution": {
          "iopub.status.busy": "2022-05-21T13:46:22.101636Z",
          "iopub.execute_input": "2022-05-21T13:46:22.102175Z",
          "iopub.status.idle": "2022-05-21T13:46:22.329453Z",
          "shell.execute_reply.started": "2022-05-21T13:46:22.102136Z",
          "shell.execute_reply": "2022-05-21T13:46:22.328730Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = str(6) + '.jpg'\n",
        "input_image = Image.open(filename)\n",
        "input_tensor = preprocess(input_image)\n",
        "show(input_tensor)\n",
        "wheel = random_noise_outside_patch(input_tensor, 90, 140, 160, 230).unsqueeze(0)\n",
        "label = random_noise_outside_patch(input_tensor, 130, 10, 180, 45).unsqueeze(0)\n",
        "mirror = random_noise_outside_patch(input_tensor, 160, 60, 220, 130).unsqueeze(0)\n",
        "windshield = random_noise_outside_patch(input_tensor, 90, 40, 200, 90).unsqueeze(0)\n",
        "side = random_noise_outside_patch(input_tensor, 0, 0, 90, 220).unsqueeze(0)\n",
        "append_features(wheel, label, mirror, windshield, side)"
      ],
      "metadata": {
        "id": "EMjqpwiJgBtT",
        "execution": {
          "iopub.status.busy": "2022-05-21T13:46:22.963665Z",
          "iopub.execute_input": "2022-05-21T13:46:22.964197Z",
          "iopub.status.idle": "2022-05-21T13:46:23.166766Z",
          "shell.execute_reply.started": "2022-05-21T13:46:22.964159Z",
          "shell.execute_reply": "2022-05-21T13:46:23.166106Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch Hooks for saving activations\n"
      ],
      "metadata": {
        "id": "hC4tflybsn_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "#                    CITATIONS                    \n",
        "# https://www.lyndonduong.com/saving-activations/\n",
        "# https://web.stanford.edu/~nanbhas/blog/forward-hooks-pytorch/#extracting-activations-from-a-layer\n",
        "#\n",
        "###############################################################################\n",
        "\n",
        "def save_adaptive_activations(\n",
        "        activations: DefaultDict,\n",
        "        name: str,\n",
        "        module: nn.Module,\n",
        "        inp: Tuple,\n",
        "        out: torch.Tensor\n",
        ") -> None:\n",
        "    \"\"\"PyTorch Forward hook to save outputs and inhibitory hidden state at each forward\n",
        "    pass. Mutates specified dict objects with each fwd pass.\n",
        "    \"\"\"\n",
        "    activations[name].append(out.detach().cpu())\n",
        "\n",
        "\n",
        "def register_activation_hooks(\n",
        "        model: nn.Module,\n",
        ") -> DefaultDict[List, torch.Tensor]:\n",
        "    \"\"\"Registers forward hooks in specified layers.\n",
        "    Parameters\n",
        "    ----------\n",
        "    model:\n",
        "        PyTorch model\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    activations_dict:\n",
        "        dict of lists containing activations of specified layers in the\n",
        "        form (k,v) where k is the name of the layer and v is a list of the \n",
        "        activation tensors in the order that they were run through the nerual \n",
        "        network\n",
        "    \"\"\"\n",
        "    activations_dict = collections.defaultdict(list)\n",
        "    hooks = []\n",
        "    for name, module in model.named_modules():\n",
        "        hooks.append(module.register_forward_hook(\n",
        "            partial(save_adaptive_activations, activations_dict, name)\n",
        "        ))\n",
        "\n",
        "    return activations_dict, hooks\n",
        "\n",
        "def remove_hooks(\n",
        "    hooks: List,\n",
        ") -> None:\n",
        "    \"\"\"Registers forward hooks in specified layers.\n",
        "    Parameters\n",
        "    ----------\n",
        "    hooks:\n",
        "        list of hooks attached to the model\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "    \"\"\"\n",
        "    for hook in hooks:\n",
        "        hook.remove()\n",
        "        \n",
        "\n",
        "# # example use \n",
        "# activations_dict, hooks = register_activation_hooks(net)\n",
        "# net(input)\n",
        "# print(activations_dict)\n",
        "# remove_activations(hooks)"
      ],
      "metadata": {
        "id": "Z7rBmMqssqGK",
        "execution": {
          "iopub.status.busy": "2022-05-21T13:46:25.067562Z",
          "iopub.execute_input": "2022-05-21T13:46:25.068085Z",
          "iopub.status.idle": "2022-05-21T13:46:25.076557Z",
          "shell.execute_reply.started": "2022-05-21T13:46:25.068050Z",
          "shell.execute_reply": "2022-05-21T13:46:25.075552Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Possible Error Functions"
      ],
      "metadata": {
        "id": "XtOMj-8zGZ15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for L2 \n",
        "# nn.MSELoss()\n",
        "\n",
        "# for L1\n",
        "# nn.L1Loss()"
      ],
      "metadata": {
        "id": "WdnzmEZ5GdG7",
        "execution": {
          "iopub.status.busy": "2022-05-21T13:46:26.265719Z",
          "iopub.execute_input": "2022-05-21T13:46:26.265987Z",
          "iopub.status.idle": "2022-05-21T13:46:26.270330Z",
          "shell.execute_reply.started": "2022-05-21T13:46:26.265957Z",
          "shell.execute_reply": "2022-05-21T13:46:26.269505Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Calculate the error between saved activation data structures"
      ],
      "metadata": {
        "id": "r6iPLafx-6hR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def matched_activations(activations, train_indices, test_ind, error_func):\n",
        "    \"\"\" Returns what the patch indices that have similar activations to patch\n",
        "    represented by test_ind\n",
        "    ----------\n",
        "    activations:\n",
        "        dict: {'layer name': List of tensors of activations}\n",
        "    \n",
        "    train_indices:\n",
        "        list of indices that represent what indices within the values of \n",
        "        activations dict lists are train indices\n",
        "\n",
        "    test_index:\n",
        "        list of indices that represent what index within the values of \n",
        "        activations dict lists are the test example\n",
        "\n",
        "    error_func:\n",
        "        func (tensor, tensor) -> int that gives error metric between tensors\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    matched_indices: (index, error)\n",
        "        sorted list of what train indices match up well with the test index, \n",
        "        sorted from lowest error to highest error\n",
        "    \"\"\"\n",
        "    matched_indices = []\n",
        "\n",
        "    for train_ind in train_indices:\n",
        "        # calculate error between train_ind and test_ind\n",
        "        train_err = 0\n",
        "        for i, name in enumerate(activations.keys()):\n",
        "            train_err += np.exp(2 * i / len(activations)) * error_func(activations[name][train_ind], activations[name][test_ind])\n",
        "        # create mew match tuple\n",
        "        new_matched_el = (train_ind, train_err)\n",
        "\n",
        "        # find index to insert new_matched_el\n",
        "        ind = len(matched_indices)\n",
        "        for i in range(len(matched_indices)):\n",
        "            if new_matched_el[1] < matched_indices[i][1]:\n",
        "              ind = i\n",
        "              break;\n",
        "\n",
        "        # insert new_matched_el into correct place in list\n",
        "        if ind == len(matched_indices):\n",
        "            matched_indices.append(new_matched_el)\n",
        "        else:\n",
        "            matched_indices = matched_indices[:i] + [new_matched_el] + matched_indices[i:]\n",
        "\n",
        "    return matched_indices\n"
      ],
      "metadata": {
        "id": "uHyS3UEg-5Nn",
        "execution": {
          "iopub.status.busy": "2022-05-21T13:46:27.209522Z",
          "iopub.execute_input": "2022-05-21T13:46:27.210105Z",
          "iopub.status.idle": "2022-05-21T13:46:27.349839Z",
          "shell.execute_reply.started": "2022-05-21T13:46:27.210064Z",
          "shell.execute_reply": "2022-05-21T13:46:27.349042Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test activation similarities between labeled features"
      ],
      "metadata": {
        "id": "1zupVRuCjZPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "activations_dict, hooks = register_activation_hooks(model)\n",
        "\n",
        "\n",
        "num_images = 6\n",
        "num_features = 5\n",
        "num_feature_images = num_images * num_features\n",
        "for wheel in wheels:\n",
        "    model(wheel)\n",
        "for label in labels:\n",
        "    model(label)\n",
        "for mirror in mirrors:\n",
        "    model(mirror)\n",
        "for windshield in windshields:\n",
        "    model(windshield)\n",
        "for side in sides:\n",
        "    model(side)\n",
        "\n",
        "start_time = time.time()\n",
        "classes = ['wheel', 'label', 'mirror', 'windshield', 'side']\n",
        "def index_to_class():\n",
        "    index_to_class_dict = {}\n",
        "    for i in range(num_feature_images):\n",
        "        index_to_class_dict[i] = classes[i//num_images]\n",
        "\n",
        "    return index_to_class_dict\n",
        "\n",
        "## TODO: DIVIDE LOSS BY NUMBER OF TRAIN IMAGES\n",
        "def class_to_score(scores, index_to_class_dict):\n",
        "    class_to_scores = {}\n",
        "    class_counters = {}\n",
        "\n",
        "    for class_name in classes:\n",
        "        class_to_scores[class_name] = 0\n",
        "        class_counters[class_name] = 0\n",
        "\n",
        "    for ind, loss in scores:\n",
        "        class_name = index_to_class_dict[ind]\n",
        "        class_to_scores[class_name] += loss\n",
        "        class_counters[class_name] += 1\n",
        "\n",
        "    for class_name, counter in class_counters.items():\n",
        "        class_to_scores[class_name] /= counter\n",
        "\n",
        "    return class_to_scores\n",
        "\n",
        "index_to_class_dict = index_to_class()\n",
        "\n",
        "incorrect_preds = 0\n",
        "for i in range(num_feature_images):\n",
        "    test_indices = list(np.arange(num_feature_images))\n",
        "    test_indices = test_indices[:i] + test_indices[i+1:]\n",
        "    matched_activation_results = matched_activations(activations_dict, test_indices, i, nn.L1Loss())\n",
        "    class_to_score_dict = class_to_score(matched_activation_results, index_to_class_dict)\n",
        "    print(f\"{index_to_class_dict[i]}, {i}: {class_to_score_dict}\")\n",
        "    predicted_class = (None, 99999999)\n",
        "    for class1, score in class_to_score_dict.items():\n",
        "        if score < predicted_class[1]:\n",
        "            predicted_class = (class1, score)\n",
        "    if predicted_class[0] != index_to_class_dict[i]:\n",
        "        incorrect_preds += 1\n",
        "    print(f\"prediction for {index_to_class_dict[i]}, {i}: {predicted_class[0]}, loss: {predicted_class[1]}\")\n",
        "\n",
        "print(f\"correct predictions for {1 - round(incorrect_preds / num_feature_images,2)}%\")"
      ],
      "metadata": {
        "id": "Xfx_pzHCjYmZ",
        "execution": {
          "iopub.status.busy": "2022-05-21T13:46:30.227482Z",
          "iopub.execute_input": "2022-05-21T13:46:30.227998Z",
          "iopub.status.idle": "2022-05-21T13:47:10.593877Z",
          "shell.execute_reply.started": "2022-05-21T13:46:30.227962Z",
          "shell.execute_reply": "2022-05-21T13:47:10.593041Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Extract Potential Features from Test Images\n",
        "\n",
        "Now that we have saved the activations of many features within the training set, we have to attempt to extract features patches from new test images that the CNN recognizes. "
      ],
      "metadata": {
        "id": "qSXRgCLGMSJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Naivly testing all possible patches of image"
      ],
      "metadata": {
        "id": "VJZhseo3MVgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'test1.jpeg'\n",
        "input_image = Image.open(filename)\n",
        "input_tensor = preprocess(input_image).to(device)\n",
        "\n",
        "def garbage_collect(activations):\n",
        "    for k, v in activations.items():\n",
        "        activations[k] = v[:-1]\n",
        "\n",
        "def extract_all_patches(img):\n",
        "    train_indices = list(np.arange(num_feature_images))  \n",
        "    width = img.size()[2]\n",
        "    height = img.size()[1]\n",
        "    # dict that maps feature to patch with minimum loss in the form \"class\":(dim, x, y, loss)\n",
        "    feature_mins = {}\n",
        "    for i in range(num_features):\n",
        "        feature_mins[index_to_class_dict[i*num_images]] = (0,0,0,9999999999)\n",
        "    # iterate through all the possible dimensions, and coordinates\n",
        "    for dim in [20, 40, 80]:\n",
        "        for x in range(0, width-dim, 10): ## 5\n",
        "            for y in range(0, height-dim, 10): ## 5\n",
        "                print(dim, x, y)\n",
        "                # create test patch\n",
        "                test_patch = random_noise_outside_patch(img, x, y, x+dim, y+dim)\n",
        "                # run test patch through nn, so hooks save the activations\n",
        "                model(test_patch.unsqueeze(0).to(device))\n",
        "                #indices for \n",
        "                matched_activation_results = matched_activations(activations_dict, train_indices, -1, nn.L1Loss())\n",
        "                class_to_score_dict = class_to_score(matched_activation_results, index_to_class_dict)\n",
        "                for feat, loss in class_to_score_dict.items():\n",
        "                    if loss < feature_mins[feat][3]:\n",
        "                        feature_mins[feat] = (dim, x, y, loss)\n",
        "                garbage_collect(activations_dict)\n",
        "\n",
        "    return feature_mins\n",
        "\n",
        "start_time = time.time()\n",
        "extracted_patches = extract_all_patches(input_tensor)\n",
        "print(time.time() - start_time)"
      ],
      "metadata": {
        "id": "_qfXeXjeM48G",
        "execution": {
          "iopub.status.busy": "2022-05-21T13:47:19.177917Z",
          "iopub.execute_input": "2022-05-21T13:47:19.178578Z",
          "iopub.status.idle": "2022-05-21T14:06:46.214471Z",
          "shell.execute_reply.started": "2022-05-21T13:47:19.178542Z",
          "shell.execute_reply": "2022-05-21T14:06:46.213600Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(img) -> None:\n",
        "    \"\"\"\n",
        "    View multiple images stored in files, stacking vertically\n",
        "\n",
        "    Arguments:\n",
        "        filename: str - path to filename containing image\n",
        "    \"\"\"\n",
        "    # <something gets done here>\n",
        "    plt.figure()\n",
        "    npimg = img.cpu().numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
        "\n",
        "show_images(input_tensor)\n",
        "\n",
        "def print_extracted_patches(extracted_patches, img):\n",
        "    for feature_name, (dim, x, y, loss) in extracted_patches.items():\n",
        "        patch = random_noise_outside_patch(img, x, y, x+dim, y+dim)\n",
        "        print(f\"the extracted patch for {feature_name} is at dim:{dim}, x:{x}, y:{y}, with loss: {loss}\")\n",
        "        show_images(patch)\n",
        "print_extracted_patches(extracted_patches, input_tensor)"
      ],
      "metadata": {
        "id": "ki6az8gdaA6b",
        "execution": {
          "iopub.status.busy": "2022-05-21T14:08:50.404773Z",
          "iopub.execute_input": "2022-05-21T14:08:50.405444Z",
          "iopub.status.idle": "2022-05-21T14:08:51.729580Z",
          "shell.execute_reply.started": "2022-05-21T14:08:50.405408Z",
          "shell.execute_reply": "2022-05-21T14:08:51.728755Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'test2.jpeg'\n",
        "input_image = Image.open(filename)\n",
        "input_tensor = preprocess(input_image).to(device)\n",
        "start_time = time.time()\n",
        "extracted_patches = extract_all_patches(input_tensor)\n",
        "print(time.time() - start_time)"
      ],
      "metadata": {
        "id": "8eKJM2FSqoOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_images(input_tensor)\n",
        "print_extracted_patches(extracted_patches, input_tensor)"
      ],
      "metadata": {
        "id": "NUvE7xsQ9pFw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}